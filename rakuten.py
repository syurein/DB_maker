import pandas as pd
import requests
import google.generativeai as genai
import time
import json
import random
import os
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# 1. è¤‡æ•°ã®GAS Manager URL (ãƒªã‚¹ãƒˆå½¢å¼)
# è¤‡æ•°ã‚ã‚‹å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿½åŠ ã—ã¦ãã ã•ã„
GAS_MANAGER_URLS = [
    "https://script.google.com/macros/s/AKfycbz9QRefEYzM6P_WVNa5M1J_99Ak3RYNqbWfve61cLDwAUXHhwhgjfcpvR94BK18LbYD/exec",
    # "https://script.google.com/macros/s/xxxxx.../exec", 
]

# 2. å…¥å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
INPUT_CSV = "./MercariScraper/merged_data_total_6542.csv"
OUTPUT_CSV = "results_parallel.csv"

# 3. æ­£è¦è¡¨ç¾ãƒ•ã‚£ãƒ«ã‚¿ (å‡¦ç†ã—ãŸã„å•†å“åã®æ¡ä»¶)
# ä¾‹: ".*" (ã™ã¹ã¦), "ã‚½ãƒ‹ãƒ¼|Sony", "iPhone.*128GB"
REGEX_PATTERN = ".*" 

# 4. ä¸¦åˆ—å‡¦ç†ã®è¨­å®š
MAX_WORKERS = 3       # åŒæ™‚ã«å‹•ã‹ã™ã‚¹ãƒ¬ãƒƒãƒ‰æ•° (å¢—ã‚„ã—ã™ãã‚‹ã¨APIåˆ¶é™ã«ã‹ã‹ã‚Šã¾ã™)
SAVE_INTERVAL = 10    # ä½•ä»¶ã”ã¨ã«ä¿å­˜ã™ã‚‹ã‹

# ==========================================
# AIã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# ==========================================
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash')

def generate_search_keyword(product_name):
    """å•†å“åã‹ã‚‰æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
    prompt = f"""
    ã‚ãªãŸã¯ECã‚µã‚¤ãƒˆã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
    ä»¥ä¸‹ã®å•†å“åã‹ã‚‰ã€æ¥½å¤©å¸‚å ´ã§ä¾¡æ ¼èª¿æŸ»ã‚’ã™ã‚‹ãŸã‚ã®ã€Œæœ€ã‚‚ç²¾åº¦ã®é«˜ã„æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã‚’1ã¤ã ã‘æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    å‹ç•ªãŒã‚ã‚‹å ´åˆã¯å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªèª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
    
    å•†å“å: {product_name}
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
    """
    try:
        # ä¸¦åˆ—å‡¦ç†æ™‚ã®APIåˆ¶é™å›é¿ã®ãŸã‚å°‘ã—ãƒ©ãƒ³ãƒ€ãƒ ã«å¾…æ©Ÿ
        time.sleep(random.uniform(0.5, 1.5))
        response = model.generate_content(prompt)
        keyword = response.text.strip()
        return keyword
    except Exception as e:
        print(f"âŒ AI Error ({product_name}): {e}")
        return product_name

def fetch_prices_from_gas(keyword):
    """ãƒ©ãƒ³ãƒ€ãƒ ãªGAS Managerã‚’é¸ã‚“ã§ä¾¡æ ¼ã‚’å–å¾—"""
    target_url = random.choice(GAS_MANAGER_URLS) # URLã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠã—ã¦è² è·åˆ†æ•£
    try:
        response = requests.get(target_url, params={"q": keyword}, timeout=45)
        data = response.json()
        prices = data.get("prices", [])
        return prices
    except Exception as e:
        print(f"âŒ GAS Error ({keyword}): {e}")
        return []

def process_single_item(row):
    """1è¡Œåˆ†ã®å‡¦ç†ã‚’è¡Œã†é–¢æ•° (ä¸¦åˆ—å®Ÿè¡Œç”¨)"""
    original_name = row['å•†å“å'] # CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«åˆã‚ã›ã¦å¤‰æ›´
    
    # 1. AIã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åŒ–
    search_keyword = generate_search_keyword(original_name)
    
    # 2. GASã¸å•ã„åˆã‚ã›
    price_list = fetch_prices_from_gas(search_keyword)
    
    # 3. çµ±è¨ˆè¨ˆç®—
    count = len(price_list)
    if count > 0:
        min_price = min(price_list)
        max_price = max(price_list)
        avg_price = sum(price_list) / count
    else:
        min_price = max_price = avg_price = 0

    print(f"âœ… Finished: {search_keyword} -> {count}ä»¶ (Min: {min_price}å††)")

    return {
        "original_name": original_name,
        "search_keyword": search_keyword,
        "count": count,
        "min_price": min_price,
        "max_price": max_price,
        "avg_price": int(avg_price),
        "raw_prices": str(price_list)
    }

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
def main():
    # 1. CSVèª­ã¿è¾¼ã¿
    try:
        df = pd.read_csv(INPUT_CSV)
        print(f"ğŸ“‚ CSV loaded: {len(df)} items")
    except FileNotFoundError:
        print(f"âŒ Error: {INPUT_CSV} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # 2. æ­£è¦è¡¨ç¾ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if REGEX_PATTERN and REGEX_PATTERN != ".*":
        print(f"ğŸ” Filtering with regex: '{REGEX_PATTERN}'")
        df = df[df['å•†å“å'].str.contains(REGEX_PATTERN, regex=True, case=False, na=False)]
    
    print(f"ğŸ‘‰ Target items: {len(df)} items")
    
    results = []
    
    # 3. ä¸¦åˆ—å‡¦ç†ã®é–‹å§‹
    print(f"ğŸš€ Starting parallel processing (Max workers: {MAX_WORKERS})...")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # ã‚¿ã‚¹ã‚¯ã®ç™»éŒ²
        future_to_row = {executor.submit(process_single_item, row): index for index, row in df.iterrows()}
        
        completed_count = 0
        
        for future in as_completed(future_to_row):
            try:
                data = future.result()
                results.append(data)
            except Exception as e:
                print(f"âŒ Unexpected Error: {e}")
            
            completed_count += 1
            
            # 4. å®šæœŸä¿å­˜ (SAVE_INTERVALä»¶ã”ã¨)
            if completed_count % SAVE_INTERVAL == 0:
                print(f"ğŸ’¾ Saving progress... ({completed_count}/{len(df)})")
                save_df = pd.DataFrame(results)
                save_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')

    # 5. æœ€çµ‚ä¿å­˜
    save_df = pd.DataFrame(results)
    save_df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ All Done! Results saved to {OUTPUT_CSV}")

if __name__ == "__main__":
    main()